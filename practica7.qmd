---
title: "Problema 5"
subtitle: "20582- Análisis de Datos para el GMAT"
author: Biel Bauzà, Marc Arrom, Eulàlia Tous i Rebeca Payà
date: today
format:
  html:
    theme: lumen
    toc: true
    toc-depth: 3
Rendering:
    embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Enunciat

La tabla de [datos_antropométricos](https://github.com/igmuib/Practica_AD/blob/main/datos_antropometricos.csv) presenta un conjunto de datos simulados que recopila información sobre 200 observaciones de hombres y mujeres. Este conjunto incluye las siguientes variables:

-   `altura`: Altura en centímetros
-   `peso`: Peso en kilogramos
-   `cintura`: Circunferencia de la cintura en centímetros
-   `cadera`: Circunferencia de la cadera en centímetros
-   `IMC`: Índice de Masa Corporal (IMC)
-   `grasa_corporal`: Porcentaje de grasa corporal

Presentad un análisis exploratorio de los datos junto con un resumen de lo observado en el contexto del problema. Aplicad técnicas de clustering para agrupar individuos que tengan formas de cuerpos semejantes. Escribid una conclusión del análisis realizado en el contexto del problema

```{r, echo=FALSE}
library(readr) # Para lectura de datos csv.
library(dplyr)
library(tidyverse)
library(ggcorrplot) # Para la creación del gráfico de correlación
library(GGally) # Para comparar variables a pares (ggpairs)
library(scales) # Para editar gráficos (cambiar ancho del histograma)
library(factoextra) # Para hacer el mapa de calor y usar el metodo del codo 
library(cluster)

```

```{r, include=FALSE}
datos <- read_csv("datos_antropometricos.csv")
head(datos)
datos_numericos<-datos %>% select(2:7)
```

# Anàlisi descriptiu de les dades

En aquest apartat tractarem de fer una visualització general de les dades i el seu comportament entre elles, com ara estudiar la seua correlació i mitjanes separat per sexe. A continuació mostrarem un parell de gràfiques on podrem veure el comportament de les nostres dades d'una forma més intuitiva i visual.

```{r, echo=FALSE}
# Calcular la matriz de correlación
matriz_correlacion <- cor(datos %>%
                            select("altura","peso","cintura","cadera","IMC","grasa_corporal")
                          )

# Generar el gráfico de correlación
ggcorrplot(matriz_correlacion, 
           hc.order = TRUE,         # Ordenar jerárquicamente
           type = "lower",          # Mostrar solo la mitad inferior
           lab = TRUE,              # Añadir los valores de correlación
           lab_size = 3.5,          # Tamaño del texto de los valores
           colors = c("#4575b4", "#f7f7f7", "#d73027")) +  # Colores personalizados
  ggtitle("Mapa de Correlació de Variables") +    # Añadir título
  labs(x = "Variables", y = "Variables") +         # Títulos de los ejes
  theme(plot.title = element_text(hjust = 0.5, size = 16),   # Centrar el título y ajustar tamaño
        axis.title.x = element_text(size = 14),   # Tamaño del título del eje x
        axis.title.y = element_text(size = 14))   # Tamaño del título del eje y

```
Podem observar que les variables d'altura i cintura tenen una correlació positiva molt alta respecte la resta, altres variables que també tenen una alta correlació positiva és el pes amb l'altura i cintura, fet del qual té prou sentit. D'altra banda, podem veure que la grasa corporal té una alta correlació negativa amb el pes, l'altura i la cintura.


```{r, include=FALSE}
ggpairs(
  datos, 
  aes(color = sexo, alpha = 0.7),
  upper = list(continuous = wrap("cor", size = 3)),  # Tamaño del texto de correlación
  diag = list(continuous = wrap("densityDiag")),
  lower = list(continuous = wrap("points", size = 0.5))
) +
  scale_color_brewer(palette = "Set2", name = "Sexo") +
  labs(
    title = "Gráfico de Pares por Sexo",
    subtitle = "Relación entre variables en función del sexo"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
    plot.subtitle = element_text(size = 10, hjust = 0.5),
    strip.text = element_text(size = 8),
    axis.text = element_text(size = 7)
  )
```
```{r, echo=FALSE}
ggpairs(datos,aes(color=sexo, alpha=0.5))
```

Analitzem primer les variables de forma individual.

-   Podem observar com la majoria pareixen seguir una distribució normal aproximada, però s'haurien de fer contratos d'hipòtesis per poder afirmar-ho.
-   Separant les dades en funció del sexe observem que l'altura, el pes i la cintura tenen valors més alts en el cas dels homes, mentre que la majoria de dones tenen una grasa corporal superior. Els valors de la cadera i del IMC són similars als dos casos, encara que la mitjana continua sent major en el cas de les dones.

En cuanto al análisis por pares tenemos

-   En las variables **altura**, **peso** y **cintura** observamos que los datos estan agrupados por sexo. Posteriormente, en el clustering, lo analizaremos.
-   En las correlaciones, destacan
    - La correlación positiva entre: **peso** y **altura**; **cintura** y **altura** ; **cintura** y **peso**.
    - La correlación negativa entre: **grasa corporal** y **altura**; **grasa corporal** y **peso** ; **grasa corporal** y **cintura**.
    - Mencionar que sorprende la baja correlación del **IMC** con la **altura** y el **peso**, ya que el IMC se calcula siguiendo la fórmula $IMC = \frac{peso}{altura^2}$.
    
```{r, echo=FALSE}
# Calcular la matriz de distancia
distancia <- dist(datos_numericos, method = "manhattan")  # Cambia "euclidean" si prefieres otro método

# Visualizar el mapa de calor de distancias
fviz_dist(as.dist(distancia), 
          gradient = list(low = "blue", mid = "white", high = "red"),
          lab_size = 8) +
  ggtitle("Mapa de Calor de Distancias") +
  theme_minimal()+
  theme(
    axis.text.x = element_blank(), # Quitar texto del eje X
    axis.text.y = element_blank()
  )
```

Las celdas azules indican observaciones con baja distancia, es decir, son valores similares entre sí. Las celdas rojas muestran observaciones con grandes distancias, ed decir, valores diferentes entre sí. Las celdas blancas representan valores intermedios de distancia.

Si se observan bloques azules a lo largo de la diagonal, esto indica la presencia de grupos de observaciones similares, lo que quiere decir que pueden ser posibles clústeres.

## Mètode codo i visualtizació de cluster amb diferents distáncies

Similar al ejemplo 5.2.5 al tener datos con procedemos a escalarlos, usaremos el método del codo para obtener el número de clusters óptimo. Primero probaremos usando la distáncia euclidea.

```{r, echo=FALSE}
escalado<-scale(datos_numericos)
fviz_nbclust(x = escalado, FUNcluster = kmeans, method = "wss",
             diss = dist(datos, method = "euclidean")) +
  geom_vline(xintercept = 4, linetype = 2)
```

Parece razonable pues escoger $k=4$ como número de clusters, ahora fijemos una semilla i veamos si los datos se comportan bien con este número de clusters. También calcularemos los puntos iniciales del algoritmo.

```{r, echo=FALSE}
set.seed(10)
centro_cluster<-kmeans(x=escalado,centers = 4,nstart = 25)
```

Al tener en total 6 variables el código reducirá la dimensión de estos usando sus dos primeras componenetes principales.

```{r, echo=FALSE}
fviz_cluster(object = centro_cluster, data = escalado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

De manera directa podemos ver que entre el verde y rojo hay muchissimos valores solapados, lo que nos indica que un valor menor de clusters implicará un mejor resultado, al haber intersecciones tanto en los clusters azul-lila como verde-rojo veamos como resulta el clustering con $k=2$.

```{r, echo=FALSE}
centro_cluster_1<-kmeans(x=escalado,centers = 2,nstart = 25)
fviz_cluster(object = centro_cluster_1, data = escalado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

Este clustering nos definiria dos tipos de cuerpo pero debemos notar que la variabilidad definida por las componenetes principales es $56.8\%<75\%$ por lo que no seria un modelo muy fiable. Esta falta de variabilidad puede ser debido al uso de k-medias o la distancia euclidiana, como podemos notar hay muchos valores lejanos al centro del cluster, en este caso será mas robusto el uso de k-medoides.

Al tener valores lejanos el metodo "manhattan" resultará mas apto para el cálculo del número de clusters

```{r, echo=FALSE}
fviz_nbclust(x = escalado, FUNcluster = pam, method = "wss",
             diss = dist(datos, method = "manhattan"))
```

Para encontrar los clusters por k-medoides usaremos la función "pam" con $k=2$, de nuevo usamos la metrica "manhattan" por la presencia de dispersión entre valores.

```{r, echo=FALSE}
medoide_clusters <- pam(x = escalado, k = 2, metric = "manhattan")
medoide_clusters
```

El primer bloque muestra los medoides, los puntos centrales de cada clúster. Estos puntos son seleccionados para ser los más representativos de cada clúster..

El segundo bloque muestra el vector de clustering de las observaciones.Cada observación está asignada a un clúster. El vector contiene el número de clúster asignado a cada observación. Como tenemos que  $ k=2$, tenemos dos clústeres en total: el clúster 1 y el clúster 2.

En el tercer bloque vemos los valores de build y swap. Build nos indica el valor de la suma total de las distancias entre las observaciones y los centros de los clústeres. Swap es el valor de la suma total de las distancias después de que el algoritmo intenta mejorar el clustering al intercambiar los centros de los clústers.

El valor de la función objetivo ha disminuido de 4.258150 a 3.916516 después de realizar el cambio de los medoids. Esto indica que el algoritmo ha logrado una mejor asignación de los clústeres al minimizar la suma de las distancias dentro de los clústeres.

Veamos una representación gráfica del clustering dado por la función "pam":

```{r, echo=FALSE}
fviz_cluster(object = medoide_clusters, data = escalado, ellipse.type = "t", repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

Veamos si obviando algunas variables podemos encontrar un modelo que tenga mayor representación de variabilidad en las componenetes principales. Debido a la alta relación de las variables podemos ver con la matriz de corelaciones que las varaibles con mas peso son altura,peso y cintura. Por ejemplo el IMC está completamente definido por el peso y la altura.

```{r}
mios<-datos %>% select("altura","peso","cintura")
fviz_nbclust(x = mios, FUNcluster = pam, method = "wss",
             diss = dist(datos, method = "manhattan"))
```

Por el método del codo el valor $k=2$ dará los mejores resultados además de evitar solapamientos como antes.

```{r}
medoide_clusters <- pam(x = mios, k = 2, metric = "manhattan")
medoide_clusters
fviz_cluster(object = medoide_clusters, data = mios, ellipse.type = "t", repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```
Así obtenemos una variabilidad total de $83.6\%$ con un solapamiento tolerable comparado con los valores de $k$ mayores.

```{r, echo=FALSE}
medoide_clusters
```


```{r, echo=FALSE}
datos <- datos %>%
  mutate(cluster = medoide_clusters$clustering)

# Crear tabla de contingencia
tabla_contingencia <- table(datos$sexo, datos$cluster)

# Ver la tabla
print(tabla_contingencia)

```

Esto nos indica que hay 178 hombres en el clúster 1 y 22 hombres en el clúster 2. Ademas, hay 6 mujeres en el clúster 1 y 194 mujeres en el clúster 2. Como la mayoría de los hombres se encuentran en un clúster y la mayoría de las mujeres en el otro, se puede ver una clara separación entre los sexos en los diferentes clústers. Esto indicaría que el modelo ha logrado identificar diferencias entre sexos y ha agrupado las observaciones en función de estas diferencias.

Por lo tanto podemos deducir que el cluster ha conseguido separar los sexo de una forma bastante buena. Así y todo hay algunos casos minoritarios excepcionales que pueden ser debidos a la diversidad genética y al hecho que pueden existir personas con alturas anormales para lo que estaria asociado a su sexo.