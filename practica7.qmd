---
title: "Ejercicios para exponer"
subtitle: "20582- Análisis de Datos para el GMAT"
date: today
format:
  html:
    theme: lumen
    toc: true
    toc-depth: 3
Rendering:
    embed-resources: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Problema 5 - Enunciado

La tabla de [datos_antropométricos](https://github.com/igmuib/Practica_AD/blob/main/datos_antropometricos.csv) presenta un conjunto de datos simulados que recopila información sobre 200 observaciones de hombres y mujeres. Este conjunto incluye las siguientes variables:

-   `altura`: Altura en centímetros
-   `peso`: Peso en kilogramos
-   `cintura`: Circunferencia de la cintura en centímetros
-   `cadera`: Circunferencia de la cadera en centímetros
-   `IMC`: Índice de Masa Corporal (IMC)
-   `grasa_corporal`: Porcentaje de grasa corporal

Presentad un análisis exploratorio de los datos junto con un resumen de lo observado en el contexto del problema. Aplicad técnicas de clustering para agrupar individuos que tengan formas de cuerpos semejantes. Escribid una conclusión del análisis realizado en el contexto del problema

# Librerias y carga de datos

```{r}
library(readr)
library(dplyr)
library(tidyverse)
library(ggcorrplot) # Para la creación del gráfico de correlación
library(scales) # Para editar gráficos (cambiar ancho del histograma)
library(factoextra) # Para usar el metodo del codo
library(cluster)
```

```{r}
datos <- read_csv("datos_antropometricos.csv")
head(datos)
```

# Analisis descriptivo de los datos


```{r}
grafico_altura = datos %>%
  ggplot(aes(x = altura)) + 
  geom_histogram(color = "black", alpha = 1, binwidth = 1, size = 0.5) +
  
  # Títulos
  ggtitle("Distribución de altura") +
  labs(x = "Altura (cm)", y = "Frecuencia") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 21, face = "bold", hjust = 0.5), # Título principal
    axis.text.x = element_text(size = 10),  # Tamaño del texto del eje X
    axis.text.y = element_text(size = 14),  # Tamaño del texto del eje Y
    axis.title.x = element_text(size = 18), # Tamaño del título del eje X
    axis.title.y = element_text(size = 18),  # Tamaño del título del eje Y
    legend.text = element_text(size = 15),  # Tamaño del texto de la leyenda
    legend.title = element_text(size = 18), # Tamaño y estilo del título de la leyenda
    legend.key.size = unit(0.7, "cm"),  # Tamaño de las claves de la leyenda
    legend.position = "top"  # Posición de la leyenda
  ) +
  scale_x_continuous(breaks = pretty_breaks(n = 20))
# Gira el gráfico a horizontal
  
print(grafico_altura)
```
```{r}
grafico_altura = datos %>%
  ggplot(aes(x = altura)) + 
  # Histograma
  geom_histogram(aes(y = ..density..), color = "black", fill = "lightblue", alpha = 0.7, binwidth = 1, size = 0.5) +
  
  # Curva de densidad
  geom_density(color = "red", size = 1) +
  
  # Títulos
  ggtitle("Distribución de altura") +
  labs(x = "Altura (cm)", y = "Densidad") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 21, face = "bold", hjust = 0.5), # Título principal
    axis.text.x = element_text(size = 10),  # Tamaño del texto del eje X
    axis.text.y = element_text(size = 14),  # Tamaño del texto del eje Y
    axis.title.x = element_text(size = 18), # Tamaño del título del eje X
    axis.title.y = element_text(size = 18),  # Tamaño del título del eje Y
    legend.text = element_text(size = 15),  # Tamaño del texto de la leyenda
    legend.title = element_text(size = 18), # Tamaño y estilo del título de la leyenda
    legend.key.size = unit(0.7, "cm"),  # Tamaño de las claves de la leyenda
    legend.position = "top"  # Posición de la leyenda
  ) +
  scale_x_continuous(breaks = pretty_breaks(n = 20))

# Mostrar el gráfico
print(grafico_altura)

```   
```{r}
grafico_peso = datos %>%
  ggplot(aes(x = peso)) + 
  geom_histogram(color = "black", alpha = 1, binwidth = 2, size = 0.5) +
  
  # Títulos
  ggtitle("Distribución de peso") +
  labs(x = "Peso (Kg)", y = "Frecuencia") +
  theme_classic() +
  theme(
    plot.title = element_text(size = 21, face = "bold", hjust = 0.5), # Título principal
    axis.text.x = element_text(size = 10),  # Tamaño del texto del eje X
    axis.text.y = element_text(size = 14),  # Tamaño del texto del eje Y
    axis.title.x = element_text(size = 18), # Tamaño del título del eje X
    axis.title.y = element_text(size = 18),  # Tamaño del título del eje Y
    legend.text = element_text(size = 15),  # Tamaño del texto de la leyenda
    legend.title = element_text(size = 18), # Tamaño y estilo del título de la leyenda
    legend.key.size = unit(0.7, "cm"),  # Tamaño de las claves de la leyenda
    legend.position = "top"  # Posición de la leyenda
  ) +
  scale_x_continuous(breaks = pretty_breaks(n = 20))
# Gira el gráfico a horizontal
grafico_peso
```

**FALTA AÑADIR LOS OTROS GRÁFICOS Y ALGÚN GRÁFICO MULTIVARIANTE (Ej. ggpairs)**





```{r}
# Calcular la matriz de correlación
matriz_correlacion <- cor(datos %>%
                            select("altura","peso","cintura","cadera","IMC","grasa_corporal")
                          )

# Generar el gráfico de correlación
ggcorrplot(matriz_correlacion, 
           hc.order = TRUE,         # Ordenar jerárquicamente
           type = "lower",          # Mostrar solo la mitad inferior
           lab = TRUE,              # Añadir los valores de correlación
           lab_size = 3.5,          # Tamaño del texto de los valores
           colors = c("#4575b4", "#f7f7f7", "#d73027")) +  # Colores personalizados
  ggtitle("Mapa de Correlación de Variables") +    # Añadir título
  labs(x = "Variables", y = "Variables") +         # Títulos de los ejes
  theme(plot.title = element_text(hjust = 0.5, size = 16),   # Centrar el título y ajustar tamaño
        axis.title.x = element_text(size = 14),   # Tamaño del título del eje x
        axis.title.y = element_text(size = 14))   # Tamaño del título del eje y

```

**Metodo codo+ visualtización de cluster con diferentes distancias**

Similar al ejemplo 5.2.5 al tener datos con procedemos a escalarlos, usaremos el método del codo para obtener el número de clusters óptimo. Primero probaremos usando la distáncia euclidea.
```{r}
datos_numericos<-datos %>% select(2:7)
escalado<-scale(datos_numericos)
fviz_nbclust(x = escalado, FUNcluster = kmeans, method = "wss",
             diss = dist(datos, method = "euclidean")) +
  geom_vline(xintercept = 4, linetype = 2)
```
Parece razonable pues escoger $k=4$ como número de clusters, ahora fijemos una semilla i veamos si los datos se comportan bien con este número de clusters. También calcularemos los puntos iniciales del algoritmo.

```{r}
set.seed(10)
centro_cluster<-kmeans(x=escalado,centers = 4,nstart = 25)
```

Al tener en total 6 variables el código reducirá la dimensión de estos usando sus dos primeras componenetes principales.

```{r}
fviz_cluster(object = centro_cluster, data = escalado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

De manera directa podemos ver que entre el verde y rojo hay muchissimos valores solapados, lo que nos indica que un valor menor de clusters implicará un mejor resultado, al haber intersecciones tanto en los clusters azul-lila como verde-rojo veamos como resulta el clustering con $k=2$.

```{r}
centro_cluster_1<-kmeans(x=escalado,centers = 2,nstart = 25)
fviz_cluster(object = centro_cluster_1, data = escalado, show.clust.cent = TRUE,
             ellipse.type = "euclid", star.plot = TRUE, repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

Este clustering nos definiria dos tipos de cuerpo pero debemos notar que la variabilidad definida por las componenetes principales es $56.8\%<75\%$ por lo que no seria un modelo muy fiable. Esta falta de variabilidad puede ser debido al uso de k-medias o la distancia euclidiana, como podemos notar hay muchos valores lejanos al centro del cluster, en este caso será mas robusto el uso de k-medoides.

Al tener valores lejanos el metodo "manhattan" resultará mas apto para el cálculo del número de clusters
```{r}
fviz_nbclust(x = escalado, FUNcluster = pam, method = "wss",
             diss = dist(datos, method = "manhattan"))
```

Para encontrar los clusters por k-medoides usaremos la función "pam" con $k=2$, de nuevo usamos la metrica "manhattan" por la presencia de dispersión entre valores.

```{r}
medoide_clusters <- pam(x = escalado, k = 2, metric = "manhattan")
medoide_clusters
```
Aqui falta fer una explicació del que es veu aquí!!!!!!!!!!!!

Veamos una representación gráfica del clustering dado por la función "pam":

```{r}
fviz_cluster(object = medoide_clusters, data = escalado, ellipse.type = "t", repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

Veamos si obviando algunas variables podemos encontrar un modelo que tenga mayor representación de variabilidad en las componenetes principales. Debido a la alta relación de las variables podemos ver con la matriz de corelaciones que las varaibles con mas peso son altura,peso y cintura. Por ejemplo el IMC está completamente definido por el peso y la altura.
```{r}
mios<-datos %>% select("altura","peso","cintura")
fviz_nbclust(x = mios, FUNcluster = pam, method = "wss",
             diss = dist(datos, method = "manhattan"))
```
Por el metodo del codo el valor $k=2$ dará los mejores resultados además de evitar solapamientos como antes.

```{r}
medoide_clusters <- pam(x = mios, k = 2, metric = "manhattan")
medoide_clusters
fviz_cluster(object = medoide_clusters, data = mios, ellipse.type = "t", repel = TRUE) +
  theme_bw() + theme(legend.position = "none")
```

Así obtenemos una variabilidad total de $83.6\%$ con un solapamiento tolerable comparado con los valores de $k$ mayores.